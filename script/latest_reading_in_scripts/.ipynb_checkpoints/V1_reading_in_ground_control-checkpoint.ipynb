{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "####################Import all packages######################################\n",
    "#############################################################################\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "#import missingno as msno\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import pandas_profiling as pp\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# Set working directory\n",
    "#############################################################################\n",
    "# Make Jupyter Notebook show ALL output of a cell, not only the last one\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_all_csvs_in_folder(path):\n",
    "    ''' Function reading in all CSV files in a given folder.\n",
    "        1. First lists all files in folder.\n",
    "        2. Then reads in only files which are NOT of file size = 0 and contain headers + AT LEAST 1 row of data\n",
    "        3. Appends all files into a final dataframe\n",
    "        4. Also prints the amount of files in the folder, and the amount of files used for the final dataframe.\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    import glob\n",
    "    import os\n",
    "    # Create list containing all files names of the current folder\n",
    "    all_files = glob.glob(path + \"/*.csv\")\n",
    "    # These empty lists will be filled with:\n",
    "    # 1. the names of the CSV files we want to append/merge, \n",
    "    # 2. 2 lists containing numbers representing all the files that were empty (or headers but no row data) and not read\n",
    "    \n",
    "    list_with_dfs = []\n",
    "    zero_files = []\n",
    "    empty_files = []\n",
    "    empty_row_files = []\n",
    "    filename_list = []\n",
    "    n_files_appended = 0\n",
    "    \n",
    "    print('')\n",
    "    print('')\n",
    "    print('#####################################################')\n",
    "    print('STARTING READ IN')\n",
    "    print('#####################################################')\n",
    "    print('')\n",
    "    \n",
    "    for filename in all_files:        \n",
    "        print('Reading current file:')\n",
    "        print(filename)\n",
    "        # Check whether the CSV file is larger than 0Bytes (if not, it has for sure no data and will break during read in)\n",
    "        try:        \n",
    "            if os.path.getsize(filename) == 0:\n",
    "                zero_files.append(filename)                \n",
    "                print('')\n",
    "                print('------------------------------------------------------')\n",
    "                print('!!! SKIPPING FILE: ' + filename)\n",
    "                print('    REASON: FILE SIZE == 0')\n",
    "                print('------------------------------------------------------')\n",
    "                print('')\n",
    "            if os.path.getsize(filename) > 0:\n",
    "                df = pd.read_csv(filename, index_col=None, header=0)            \n",
    "                if df.empty:\n",
    "                    empty_row_files.append(filename)\n",
    "                    print('')\n",
    "                    print('------------------------------------------------------')\n",
    "                    print('!!! SKIPPING FILE: ' + filename)\n",
    "                    print('    REASON: FILE CONTAINS NO ROW DATA')\n",
    "                    print('------------------------------------------------------')\n",
    "                    print('')\n",
    "                # Check whether the CSV is empty (this ALSO works when it DOES have headers, but no row data. This is important!)\n",
    "                if not df.empty:\n",
    "                    list_with_dfs.append(df)\n",
    "                    n_files_appended = n_files_appended + 1\n",
    "                    filename_list.append(filename)\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print('')\n",
    "            print('------------------------------------------------------')\n",
    "            print('!!! SKIPPING FILE: ' + filename)\n",
    "            print('    REASON: FILE ENTIRELY EMPTY WITHOUT HEADERS')\n",
    "            print('------------------------------------------------------')\n",
    "            print('')\n",
    "            empty_files.append(filename)            \n",
    "            pass\n",
    "    \n",
    "    # Merge all files in the file list\n",
    "    frame = pd.concat(list_with_dfs, axis=0, ignore_index=True)\n",
    "    print('')\n",
    "    print('#####################################################')\n",
    "    print('!!! DONE READING & MERGING DATA !!!')\n",
    "    print('#####################################################')\n",
    "    print('')\n",
    "    print('------------------------------------------------------')\n",
    "    print('All files: ' + str(len(all_files)))    \n",
    "    print('')\n",
    "    print('Successfully appended files: ' + str(n_files_appended))\n",
    "    print('------------------------------------------------------')\n",
    "    print('------------------------------------------------------')\n",
    "    print('')\n",
    "    print('Empty files without headers: ' + str(len(empty_files)))\n",
    "    #print(len(empty_files))\n",
    "    print(empty_files)\n",
    "    print('')\n",
    "    print('Zero size files: ' + str(len(zero_files)))\n",
    "    #print(len(zero_files))\n",
    "    print(zero_files)\n",
    "    print('')\n",
    "    print('Empty row files: ' + str(len(empty_row_files)))\n",
    "    #print(len(empty_row_files))\n",
    "    print(empty_row_files)\n",
    "    print('')    \n",
    "    print('#####################################################')\n",
    "    \n",
    "    return frame    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read in files and merge them\n",
    "path_control = '/home/taco/Documents/greta_forarex/new_data/postflight_control_FINAL/Ground control_raw_20190817/'\n",
    "control= read_all_csvs_in_folder(path_control)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202441, 70)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove all unncessary columns\n",
    "cols_to_keep = ['timeStamp',\n",
    "                'Exp0_OxygenTemp', 'Exp0_OxygenpercentO2', 'Exp0_PhValue',\n",
    "                'Exp1_OxygenTemp', 'Exp1_OxygenpercentO2',\n",
    "                'Pressure_LateAccess']\n",
    "\n",
    "#pre_and_flight = pre_and_flight[cols_to_keep]\n",
    "control = control[cols_to_keep]\n",
    "#extra = extra[cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFs contain negligible amount of missing values (NAs), just drop them\n",
    "#import missingno as msno\n",
    "#msno.matrix(postflight_1)\n",
    "#pre_and_flight.dropna(inplace=True)\n",
    "postflight_1.dropna(inplace=True)\n",
    "#extra.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive DateTime TimeStamp needs to be increased by 1hour (UTC+1 for Sweden) compared to what was recorded (apparently UTC, UK)\n",
    "#pre_and_flight.loc[:,'timeStamp'] = pd.to_datetime(pre_and_flight.timeStamp, unit='s')\n",
    "control.loc[:,'timeStamp'] = pd.to_datetime(control.timeStamp, unit='s')\n",
    "#extra.loc[:,'timeStamp'] = pd.to_datetime(extra.timeStamp, unit='s').dt.tz_localize('UTC').dt.tz_convert('Europe/Stockholm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-05-21 20:25:41')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-06-27 08:30:05')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data range of the final timestamps\n",
    "control.timeStamp.min()\n",
    "control.timeStamp.max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "control.sort_values('timeStamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "control.reset_index(inplace=True, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different time epochs for convenient plotting & exploration\n",
    "# Postflight\n",
    "control.loc[:, 'year'] = control.timeStamp.dt.year\n",
    "control.loc[:, 'month'] = control.timeStamp.dt.month\n",
    "control.loc[:, 'day'] = control.timeStamp.dt.day\n",
    "control.loc[:, 'hour'] = control.timeStamp.dt.hour\n",
    "control.loc[:, 'minute'] = control.timeStamp.dt.minute\n",
    "control.loc[:, 'second'] = control.timeStamp.dt.second\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>Exp0_OxygenTemp</th>\n",
       "      <th>Exp0_OxygenpercentO2</th>\n",
       "      <th>Exp0_PhValue</th>\n",
       "      <th>Exp1_OxygenTemp</th>\n",
       "      <th>Exp1_OxygenpercentO2</th>\n",
       "      <th>Pressure_LateAccess</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-21 20:25:41</td>\n",
       "      <td>23.298</td>\n",
       "      <td>21.106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.594</td>\n",
       "      <td>27.541</td>\n",
       "      <td>1005.7</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-21 20:25:51</td>\n",
       "      <td>23.288</td>\n",
       "      <td>21.147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.574</td>\n",
       "      <td>27.575</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-21 20:26:01</td>\n",
       "      <td>23.283</td>\n",
       "      <td>21.117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.550</td>\n",
       "      <td>27.520</td>\n",
       "      <td>1005.7</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-21 20:26:11</td>\n",
       "      <td>23.272</td>\n",
       "      <td>21.144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.527</td>\n",
       "      <td>27.569</td>\n",
       "      <td>1005.3</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-21 20:26:21</td>\n",
       "      <td>23.267</td>\n",
       "      <td>21.123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.514</td>\n",
       "      <td>27.464</td>\n",
       "      <td>1005.5</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timeStamp  Exp0_OxygenTemp  Exp0_OxygenpercentO2  Exp0_PhValue  Exp1_OxygenTemp  Exp1_OxygenpercentO2  Pressure_LateAccess  year  month  day  hour  minute  second\n",
       "0 2019-05-21 20:25:41           23.298                21.106           0.0           22.594                27.541               1005.7  2019      5   21    20      25      41\n",
       "1 2019-05-21 20:25:51           23.288                21.147           0.0           22.574                27.575               1005.6  2019      5   21    20      25      51\n",
       "2 2019-05-21 20:26:01           23.283                21.117           0.0           22.550                27.520               1005.7  2019      5   21    20      26       1\n",
       "3 2019-05-21 20:26:11           23.272                21.144           0.0           22.527                27.569               1005.3  2019      5   21    20      26      11\n",
       "4 2019-05-21 20:26:21           23.267                21.123           0.0           22.514                27.464               1005.5  2019      5   21    20      26      21"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale columns values \n",
    "# Postflight\n",
    "# All divided by 10000\n",
    "control.loc[:,'Exp0_OxygenTemp'] = control.Exp0_OxygenTemp/1000\n",
    "control.loc[:,'Exp1_OxygenTemp'] = control.Exp1_OxygenTemp/1000\n",
    "control.loc[:,'Exp0_OxygenpercentO2'] = control.Exp0_OxygenpercentO2/1000\n",
    "control.loc[:,'Exp1_OxygenpercentO2'] = control.Exp1_OxygenpercentO2/1000\n",
    "control.loc[:,'Exp0_PhValue'] = control.Exp0_PhValue/1000\n",
    "# Pressure divided by 10\n",
    "control.loc[:, 'Pressure_LateAccess'] = control.Pressure_LateAccess/10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to disk the merged files (not yet processed)\n",
    "# In Pickle format for fast read in\n",
    "#pre_and_flight.to_pickle('../data/experiment/merged/pre_and_flight_merged.pkl')\n",
    "control.to_pickle('../new_data/cleaned/control_clean.pkl')\n",
    "#extra.to_pickle('../data/experiment/merged/extra_merged.pkl')\n",
    "# In CSV\n",
    "#pre_and_flight.to_csv('../data/experiment/merged/pre_and_flight_merged.csv')\n",
    "control.to_csv('../new_data/cleaned/control_clean.csv')\n",
    "#extra.to_csv('../data/experiment/merged/extra_merged.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
